# ============================================================
# æ–‡ä»¶è¯´æ˜: feeding_analysis_service.py - æŠ•æ–™è‡ªåŠ¨åˆ†ææœåŠ¡ (v2.2 å›ºå®šä¸‹æ–™é€Ÿåº¦ç‰ˆ)
# ============================================================
# åŠŸèƒ½:
# 1. è‡ªåŠ¨åˆ†æ: æ¯5åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ (å®æ—¶æ€§æå‡)
# 2. æ•°æ®æº: æŸ¥è¯¢InfluxDBè¿‡å»30åˆ†é’Ÿçš„æ–™ä»“é‡é‡æ•°æ® (åŸå§‹6ç§’æ•°æ®)
# 3. ç®—æ³•: Valley-Peak-Compensation ç®—æ³• (è¯†åˆ«æŠ•æ–™äº‹ä»¶å¹¶è®¡ç®—æŠ•æ–™é‡)
# 4. å­˜å‚¨: å°†è®¡ç®—ç»“æœå­˜å› InfluxDB (measurement="feeding_records")
# 5. å»é‡: åŸºäº (device_id, valley_timestamp) çš„å†…å­˜å»é‡æœºåˆ¶
# ============================================================
# v2.2 æ ¸å¿ƒæ”¹è¿› (2026-01-27):
# - å›ºå®šä¸‹æ–™é€Ÿåº¦: çª‘7654=10kg/h, çª‘839=22kg/h (ä¸å†åŠ¨æ€è®¡ç®—)
# - è¡¥å¿è®¡ç®—: å›ºå®šä¸‹æ–™é€Ÿåº¦ Ã— æŠ•æ–™æŒç»­æ—¶é—´ (ç§’)
# - å»é‡æœºåˆ¶: å†…å­˜ç¼“å­˜å·²å¤„ç†äº‹ä»¶ï¼Œé˜²æ­¢5åˆ†é’Ÿæ£€æµ‹å¯¼è‡´é‡å¤å­˜å‚¨
# - è¾¹ç¼˜ä¿æŠ¤: æœªå®Œæˆçš„æŠ•æ–™ä¸å­˜æ•°æ®åº“ï¼Œç­‰å¾…ä¸‹æ¬¡åˆ†æ
# ============================================================
# ä¼˜åŒ–ç‚¹:
# - æ£€æµ‹é¢‘ç‡: 2å°æ—¶ â†’ 5åˆ†é’Ÿ (æå‡24å€)
# - èšåˆç²’åº¦: 30åˆ†é’Ÿ â†’ åŸå§‹æ•°æ® (6ç§’è½®è¯¢)
# - æŸ¥è¯¢çª—å£: 24å°æ—¶ â†’ 30åˆ†é’Ÿ (å‡å°‘æŸ¥è¯¢è´Ÿè½½)
# - è¾¹ç¼˜ä¿æŠ¤: å¢å¼ºæœªå®ŒæˆæŠ•æ–™çš„æ£€æµ‹é€»è¾‘
# ============================================================

import asyncio
import math
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional

from config import get_settings
from app.core.influxdb import get_influx_client, write_points_batch
from app.services.history_query_service import HistoryQueryService
from app.services.polling_service import get_latest_data
# å¼•å…¥ InfluxDB å†™å…¥ Point ç»“æ„
from influxdb_client import Point
from influxdb_client.client.write_api import SYNCHRONOUS

settings = get_settings()

class FeedingAnalysisService:
    def __init__(self):
        self._is_running = False
        self._task = None
        
        # ============================================================
        # ğŸ”§ æ ¸å¿ƒå‚æ•°ä¼˜åŒ–
        # ============================================================
        self.run_interval_minutes = 5      # è¿è¡Œé¢‘ç‡: 5åˆ†é’Ÿæ£€æµ‹ä¸€æ¬¡ (åŸ2å°æ—¶)
        self.query_window_minutes = 30     # æŸ¥è¯¢çª—å£: å›æº¯30åˆ†é’Ÿ (åŸ24å°æ—¶)
        self.use_raw_data = True           # ä½¿ç”¨åŸå§‹æ•°æ® (ä¸èšåˆ)
        
        # ============================================================
        # ç®—æ³•å‚æ•°
        # ============================================================
        self.min_feeding_threshold = 10.0  # æœ€å°æŠ•æ–™é˜ˆå€¼ (kg)
        self.rising_step_threshold = 5.0   # ä¸Šå‡æ­¥é•¿é˜ˆå€¼ (kg)
        self.drop_threshold = 5.0          # ä¸‹é™é˜ˆå€¼ (kg)
        self.lookahead_steps = 3           # å‰ç»æ­¥æ•° (é˜²æ­¢æ³¢åŠ¨è¯¯åˆ¤)
        
        # ============================================================
        # å›ºå®šä¸‹æ–™é€Ÿåº¦é…ç½® (v2.2 - ç”¨æˆ·å®šåˆ¶)
        # ============================================================
        # çª‘7654 (short_hopper): 10 kg/h
        # çª‘839 (long_hopper): 22 kg/h
        self.feed_rate_short_hopper = 10.0 / 3600.0  # kg/ç§’
        self.feed_rate_long_hopper = 22.0 / 3600.0   # kg/ç§’
        
        # ============================================================
        # å»é‡æœºåˆ¶ (v2.2 - é˜²æ­¢é‡å¤å­˜å‚¨)
        # ============================================================
        # è®°å½•å·²å¤„ç†çš„æŠ•æ–™äº‹ä»¶ (device_id, valley_time)
        # ç»“æ„: {(device_id, valley_timestamp): True}
        self.processed_events = {}
        self.max_cache_size = 1000  # æœ€å¤šç¼“å­˜1000æ¡è®°å½•
        
        # ============================================================
        # ä¼˜åŒ–å‚æ•° (v2.1)
        # ============================================================
        self.boundary_extension = 15       # è¾¹ç•Œæ‰©å±•æ—¶é—´ (åˆ†é’Ÿ)
        
        self.history_service = HistoryQueryService()

    def start(self):
        """å¯åŠ¨åå°åˆ†æä»»åŠ¡"""
        if self._is_running:
            return
        self._is_running = True
        self._task = asyncio.create_task(self._scheduled_loop())
        print(f"ğŸš€ [FeedingService] æŠ•æ–™åˆ†ææœåŠ¡å·²å¯åŠ¨ (v2.2 å›ºå®šä¸‹æ–™é€Ÿåº¦ç‰ˆ)")
        print(f"   â±ï¸  æ£€æµ‹é¢‘ç‡: {self.run_interval_minutes} åˆ†é’Ÿ")
        print(f"   ğŸ“Š æŸ¥è¯¢çª—å£: {self.query_window_minutes} åˆ†é’Ÿ")
        print(f"   ğŸ¯ æ•°æ®æ¨¡å¼: {'åŸå§‹æ•°æ®(6ç§’)' if self.use_raw_data else 'èšåˆæ•°æ®'}")
        print(f"   ğŸ“ æŠ•æ–™é˜ˆå€¼: {self.min_feeding_threshold} kg")
        print(f"   ğŸ”§ ä¸‹æ–™é€Ÿåº¦: çª‘7654={self.feed_rate_short_hopper*3600:.1f}kg/h, çª‘839={self.feed_rate_long_hopper*3600:.1f}kg/h")

    def stop(self):
        """åœæ­¢æœåŠ¡"""
        self._is_running = False
        if self._task:
            self._task.cancel()
        print(f"ğŸ›‘ [FeedingService] æŠ•æ–™åˆ†ææœåŠ¡å·²åœæ­¢")

    async def _scheduled_loop(self):
        """è°ƒåº¦å¾ªç¯"""
        # åˆæ¬¡å¯åŠ¨ç­‰å¾…30ç§’ï¼Œé¿å…å’Œç³»ç»Ÿåˆå§‹åŒ–å†²çª
        await asyncio.sleep(30)
        
        while self._is_running:
            try:
                print(f"\n{'='*60}")
                print(f"ğŸ“Š [FeedingService] å¼€å§‹æ‰§è¡ŒæŠ•æ–™åˆ†æä»»åŠ¡ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
                print(f"{'='*60}")
                
                await self._analyze_feeding_job()
                
                print(f"âœ… [FeedingService] åˆ†æä»»åŠ¡å®Œæˆï¼Œä¸‹æ¬¡è¿è¡Œåœ¨ {self.run_interval_minutes} åˆ†é’Ÿå")
            except Exception as e:
                print(f"âŒ [FeedingService] åˆ†æä»»åŠ¡å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
            
            # ç­‰å¾…è®¾å®šçš„é—´éš”
            await asyncio.sleep(self.run_interval_minutes * 60)

    async def _analyze_feeding_job(self):
        """æ‰§è¡Œå…·ä½“çš„åˆ†æé€»è¾‘ (ä¼˜åŒ–ç‰ˆ v2.1)"""
        now = datetime.now(timezone.utc)
        
        # ä¼˜åŒ–: è¾¹ç•Œæ‰©å±•ï¼Œé¿å…æ¼æ£€è·¨è¾¹ç•Œçš„æŠ•æ–™äº‹ä»¶
        extended_window = self.query_window_minutes + self.boundary_extension
        start_time = now - timedelta(minutes=extended_window)
        
        # 1. è·å–æ‰€æœ‰æ–™ä»“è®¾å¤‡ (è¿‡æ»¤ no_hopper)
        hopper_devices = self._get_hopper_devices()
        print(f"   ğŸ“‹ ç›®æ ‡è®¾å¤‡: {len(hopper_devices)} å°")
        print(f"   ğŸ• æ—¶é—´èŒƒå›´: {start_time.strftime('%H:%M:%S')} â†’ {now.strftime('%H:%M:%S')}")
        
        results = []
        total_events = 0
        
        for device_id in hopper_devices:
            # å»¶è¿Ÿ1ç§’ï¼Œé˜²æ­¢é«˜å¹¶å‘æŸ¥è¯¢
            await asyncio.sleep(1)
            
            # 2. æŸ¥è¯¢å†å²æ•°æ®
            records = self._query_history_weights(device_id, start_time, now)
            if not records:
                print(f"      âš ï¸  {device_id}: æ— æ•°æ®")
                continue
            
            print(f"      ğŸ” {device_id}: æŸ¥è¯¢åˆ° {len(records)} ä¸ªæ•°æ®ç‚¹")
                
            # 3. è®¡ç®—æŠ•æ–™é‡
            feeding_events = self._detect_and_calculate_feeding(records, device_id)
            if feeding_events:
                results.extend(feeding_events)
                total_events += len(feeding_events)
                print(f"      âœ… {device_id}: å‘ç° {len(feeding_events)} æ¬¡æŠ•æ–™")

        # 4. æ‰¹é‡ä¿å­˜ç»“æœ
        if results:
            self._save_feeding_records(results)
            print(f"\n   ğŸ’¾ æœ¬æ¬¡åˆ†æ: å…±å‘ç° {total_events} æ¬¡æŠ•æ–™äº‹ä»¶")
        else:
            print(f"\n   â„¹ï¸  æœ¬æ¬¡åˆ†æ: æœªå‘ç°æ–°çš„æŠ•æ–™äº‹ä»¶")

    def _get_hopper_devices(self) -> List[str]:
        """è·å–æ‰€æœ‰å¸¦æ–™ä»“çš„è®¾å¤‡ID"""
        # ä» polling_service çš„ latest_data è·å–è®¾å¤‡åˆ—è¡¨æœ€å‡†ç¡®
        # è¿™é‡Œç®€åŒ–é€»è¾‘: æˆ‘ä»¬çŸ¥é“æ˜¯ short_hopper_XX å’Œ long_hopper_XX
        # ä¹Ÿå¯ä»¥ä»é…ç½®è¯»å–ï¼Œæˆ–è€…ç¡¬ç¼–ç å·²çŸ¥IDè§„åˆ™
        # åŠ¨æ€è·å–æ›´å¥½ï¼š
        devices = []
        latest = get_latest_data()
        for device_id, data in latest.items():
            if "no_hopper" in device_id:
                continue
            # å¿…é¡»åŒ…å« weigh æ¨¡å—
            has_weigh = False
            if 'modules' in data:
                for m_data in data['modules'].values():
                    if m_data.get('module_type') == 'WeighSensor':
                        has_weigh = True
                        break
            
            if has_weigh:
                devices.append(device_id)
        
        # å¦‚æœè¿˜åœ¨å¯åŠ¨ä¸­æ²¡æ•°æ®ï¼Œä½¿ç”¨é¢„è®¾åˆ—è¡¨
        if not devices:
            return [
                'short_hopper_1', 'short_hopper_2', 'short_hopper_3', 'short_hopper_4',
                'long_hopper_1', 'long_hopper_2', 'long_hopper_3'
            ]
        return devices

    def _query_history_weights(self, device_id: str, start: datetime, end: datetime) -> List[Dict]:
        """
        æŸ¥è¯¢é‡é‡å†å²æ•°æ®
        
        Args:
            device_id: è®¾å¤‡ID
            start: å¼€å§‹æ—¶é—´
            end: ç»“æŸæ—¶é—´
            
        Returns:
            List[Dict]: æ•°æ®ç‚¹åˆ—è¡¨ [{"time": datetime, "value": float}, ...]
        """
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦èšåˆ
        if self.use_raw_data:
            # ä½¿ç”¨åŸå§‹æ•°æ® (6ç§’è½®è¯¢é—´éš”)
            query = f'''
            from(bucket: "{settings.influx_bucket}")
                |> range(start: {start.isoformat().replace("+00:00", "Z")}, stop: {end.isoformat().replace("+00:00", "Z")})
                |> filter(fn: (r) => r["_measurement"] == "sensor_data")
                |> filter(fn: (r) => r["device_id"] == "{device_id}")
                |> filter(fn: (r) => r["_field"] == "weight")
                |> sort(columns: ["_time"])
            '''
        else:
            # ä½¿ç”¨èšåˆæ•°æ® (å‘åå…¼å®¹)
            query = f'''
            from(bucket: "{settings.influx_bucket}")
                |> range(start: {start.isoformat().replace("+00:00", "Z")}, stop: {end.isoformat().replace("+00:00", "Z")})
                |> filter(fn: (r) => r["_measurement"] == "sensor_data")
                |> filter(fn: (r) => r["device_id"] == "{device_id}")
                |> filter(fn: (r) => r["_field"] == "weight")
                |> aggregateWindow(every: 1m, fn: mean, createEmpty: false)
                |> yield(name: "mean")
            '''
        
        try:
            result = self.history_service.query_api.query(query)
            data_points = []
            for table in result:
                for record in table.records:
                    val = record.get_value()
                    if val is not None and val > 0:  # è¿‡æ»¤æ— æ•ˆæ•°æ®
                        data_points.append({
                            "time": record.get_time(),
                            "value": float(val)
                        })
            
            # æŒ‰æ—¶é—´æ’åº
            data_points.sort(key=lambda x: x['time'])
            return data_points
        except Exception as e:
            print(f"      âŒ æŸ¥è¯¢ {device_id} å¤±è´¥: {e}")
            return []

    def _detect_and_calculate_feeding(self, records: List[Dict], device_id: str) -> List[Point]:
        """
        æ ¸å¿ƒç®—æ³•: Valley-Peak-Compensation æŠ•æ–™æ£€æµ‹ç®—æ³• (v2.2 å›ºå®šä¸‹æ–™é€Ÿåº¦ç‰ˆ)
        
        ç®—æ³•åŸç†:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  æŠ•æ–™è¿‡ç¨‹ç¤ºæ„å›¾:                                          â”‚
        â”‚                                                          â”‚
        â”‚  Weight                                                  â”‚
        â”‚    â–²                                                     â”‚
        â”‚    â”‚         Peak (æŠ•æ–™ç»“æŸ)                             â”‚
        â”‚    â”‚          â—                                          â”‚
        â”‚    â”‚         â•± â•²                                         â”‚
        â”‚    â”‚        â•±   â•²                                        â”‚
        â”‚    â”‚       â•±     â•² (æ¶ˆè€—ä¸‹é™)                            â”‚
        â”‚    â”‚      â•±       â•²                                      â”‚
        â”‚    â”‚     â•± (æŠ•æ–™)  â•²                                     â”‚
        â”‚    â”‚    â•±           â•²                                    â”‚
        â”‚    â”‚   â—             â—                                   â”‚
        â”‚    â”‚  Valley      Next Valley                            â”‚
        â”‚    â”‚  (æŠ•æ–™å¼€å§‹)                                          â”‚
        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time            â”‚
        â”‚                                                          â”‚
        â”‚  è®¡ç®—å…¬å¼ (v2.2 å›ºå®šä¸‹æ–™é€Ÿåº¦):                             â”‚
        â”‚  Total_Added = (Peak - Valley) + Compensation           â”‚
        â”‚                                                          â”‚
        â”‚  å…¶ä¸­:                                                    â”‚
        â”‚  - Valley: æŠ•æ–™å‰çš„æœ€ä½ç‚¹                                 â”‚
        â”‚  - Peak: æŠ•æ–™åçš„æœ€é«˜ç‚¹                                   â”‚
        â”‚  - Compensation: æŠ•æ–™è¿‡ç¨‹ä¸­çš„æ¶ˆè€—è¡¥å¿                      â”‚
        â”‚    = å›ºå®šä¸‹æ–™é€Ÿåº¦ (kg/ç§’) Ã— æŠ•æ–™æŒç»­æ—¶é—´ (ç§’)              â”‚
        â”‚    çª‘7654: 10 kg/h                                       â”‚
        â”‚    çª‘839:  22 kg/h                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        é€»è¾‘æµç¨‹:
        1. éå†æ•°æ®ç‚¹ï¼Œå¯»æ‰¾ä¸Šå‡èµ·ç‚¹ (Valley)
        2. è¿½è¸ªè¿ç»­ä¸Šå‡åŒºé—´ (Rising Edge)
        3. è¯†åˆ«å³°å€¼ç‚¹ (Peak)ï¼Œå¸¦å‰ç»æœºåˆ¶é˜²æ­¢æ³¢åŠ¨è¯¯åˆ¤
        4. è®¡ç®—æ¶ˆè€—è¡¥å¿ (ä½¿ç”¨å›ºå®šä¸‹æ–™é€Ÿåº¦)
        5. è®¡ç®—æ€»æŠ•æ–™é‡ = å‡€å¢é‡ + æ¶ˆè€—è¡¥å¿
        6. è¾¹ç¼˜ä¿æŠ¤: è·³è¿‡æ•°æ®æœ«å°¾æœªå®Œæˆçš„æŠ•æ–™äº‹ä»¶ (ä¸å­˜æ•°æ®åº“)
        7. å»é‡æœºåˆ¶: æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡è¯¥æŠ•æ–™äº‹ä»¶
        
        Args:
            records: é‡é‡æ•°æ®ç‚¹åˆ—è¡¨ [{"time": datetime, "value": float}, ...]
            device_id: è®¾å¤‡ID
            
        Returns:
            List[Point]: InfluxDB Point åˆ—è¡¨
        """
        events = []
        n = len(records)
        if n < 3:  # è‡³å°‘éœ€è¦3ä¸ªç‚¹ (PreValley, Valley, Peak)
            return []

        # å†·å´æœŸ: è®°å½•ä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„ Peak ç´¢å¼•ï¼Œé¿å…é‡å¤æ£€æµ‹
        last_peak_idx = -1
        
        i = 1
        while i < n:
            # è·³è¿‡å†·å´æœŸå†…çš„ç‚¹
            if i <= last_peak_idx:
                i += 1
                continue
                
            curr = records[i]
            prev = records[i-1]
            
            # ============================================================
            # æ­¥éª¤1: æ£€æµ‹ä¸Šå‡èµ·ç‚¹ (Valley)
            # ============================================================
            if curr['value'] > prev['value'] + self.rising_step_threshold:
                valley_idx = i - 1
                valley_val = prev['value']
                valley_time = prev['time']
                
                # ============================================================
                # æ­¥éª¤2: è¿½è¸ªè¿ç»­ä¸Šå‡åŒºé—´ (Rising Edge)
                # ============================================================
                peak_idx = i
                while peak_idx < n - 1:
                    next_val = records[peak_idx + 1]['value']
                    curr_val = records[peak_idx]['value']
                    
                    # ä»åœ¨ä¸Šå‡
                    if next_val >= curr_val:
                        peak_idx += 1
                        continue
                    
                    # æ£€æµ‹åˆ°ä¸‹é™ï¼Œå¯åŠ¨å‰ç»æœºåˆ¶é˜²æ­¢æ³¢åŠ¨è¯¯åˆ¤
                    if next_val < curr_val:
                        # å‰ç»æœºåˆ¶: æ£€æŸ¥æœªæ¥Nä¸ªç‚¹æ˜¯å¦æœ‰åå¼¹
                        is_fluctuation = False
                        for k in range(1, self.lookahead_steps + 1):
                            if peak_idx + 1 + k >= n:
                                break
                            future_val = records[peak_idx + 1 + k]['value']
                            if future_val >= curr_val:
                                # å‘ç°åå¼¹ï¼Œè¯´æ˜æ˜¯æ³¢åŠ¨
                                is_fluctuation = True
                                peak_idx += k
                                break
                        
                        if is_fluctuation:
                            peak_idx += 1
                            continue
                        
                        # ç¡®è®¤ä¸‹é™: åªæœ‰æ˜¾è‘—ä¸‹é™æ‰è®¤ä¸ºæŠ•æ–™ç»“æŸ
                        drop_diff = curr_val - next_val
                        if drop_diff > self.drop_threshold:
                            break
                    
                    peak_idx += 1
                
                # ============================================================
                # æ­¥éª¤3: è¾¹ç¼˜ä¿æŠ¤ (é˜²æ­¢æœªå®Œæˆçš„æŠ•æ–™äº‹ä»¶)
                # ============================================================
                if peak_idx >= n - 1:
                    # æŠ•æ–™å¯èƒ½æœªç»“æŸï¼Œç­‰å¾…æ›´å¤šæ•°æ® (ä¸å­˜æ•°æ®åº“)
                    print(f"         â³ {device_id}: æŠ•æ–™æœªå®Œæˆ (è¾¹ç¼˜æ•°æ®)ï¼Œç­‰å¾…ä¸‹æ¬¡åˆ†æ")
                    break
                
                peak_val = records[peak_idx]['value']
                peak_time = records[peak_idx]['time']
                raw_increase = peak_val - valley_val
                
                # ============================================================
                # æ­¥éª¤4: é˜ˆå€¼åˆ¤æ–­
                # ============================================================
                if raw_increase > self.min_feeding_threshold:
                    # ============================================================
                    # æ­¥éª¤5: å»é‡æ£€æŸ¥ (v2.2 - é˜²æ­¢é‡å¤å­˜å‚¨)
                    # ============================================================
                    event_key = (device_id, int(valley_time.timestamp()))
                    if event_key in self.processed_events:
                        print(f"         â­ï¸  {device_id}: æŠ•æ–™äº‹ä»¶å·²å¤„ç† (è°·åº•={valley_time.strftime('%H:%M:%S')})ï¼Œè·³è¿‡")
                        i = peak_idx + 1
                        continue
                    
                    # è®¡ç®—æŠ•æ–™æŒç»­æ—¶é—´ (ç§’)
                    duration_seconds = (peak_time - valley_time).total_seconds()
                    
                    # ============================================================
                    # æ­¥éª¤6: è®¡ç®—æ¶ˆè€—è¡¥å¿ (v2.2 - å›ºå®šä¸‹æ–™é€Ÿåº¦)
                    # ============================================================
                    feed_rate = self._get_feed_rate(device_id)  # kg/ç§’
                    compensation = feed_rate * duration_seconds
                    total_added = raw_increase + compensation
                    
                    # ============================================================
                    # æ­¥éª¤7: æ„å»º InfluxDB Point
                    # ============================================================
                    p = Point("feeding_records") \
                        .tag("device_id", device_id) \
                        .field("added_weight", float(total_added)) \
                        .field("raw_increase", float(raw_increase)) \
                        .field("compensation", float(compensation)) \
                        .field("feed_rate_kg_per_hour", float(feed_rate * 3600)) \
                        .field("duration_seconds", int(duration_seconds)) \
                        .field("valley_weight", float(valley_val)) \
                        .field("peak_weight", float(peak_val)) \
                        .time(valley_time)  # ä½¿ç”¨ Valley æ—¶é—´æˆ³å®ç°å»é‡
                    
                    events.append(p)
                    
                    # æ ‡è®°ä¸ºå·²å¤„ç†
                    self.processed_events[event_key] = True
                    
                    # æ¸…ç†ç¼“å­˜ (é˜²æ­¢å†…å­˜æº¢å‡º)
                    if len(self.processed_events) > self.max_cache_size:
                        # åˆ é™¤æœ€æ—§çš„ä¸€åŠ
                        keys_to_remove = list(self.processed_events.keys())[:self.max_cache_size // 2]
                        for key in keys_to_remove:
                            del self.processed_events[key]
                    
                    # è®¾ç½®å†·å´æœŸ
                    last_peak_idx = peak_idx
                    i = peak_idx + 1
                    
                    print(f"         âœ… æŠ•æ–™äº‹ä»¶: {valley_time.strftime('%H:%M:%S')} â†’ {peak_time.strftime('%H:%M:%S')}, "
                          f"æŠ•æ–™é‡={total_added:.1f}kg (å‡€å¢={raw_increase:.1f}kg, è¡¥å¿={compensation:.1f}kg, ä¸‹æ–™é€Ÿåº¦={feed_rate*3600:.1f}kg/h)")
                else:
                    # æœªè¶…è¿‡é˜ˆå€¼ï¼Œç»§ç»­
                    i += 1
            else:
                i += 1
                
        return events

    def _get_feed_rate(self, device_id: str) -> float:
        """
        è·å–è®¾å¤‡çš„å›ºå®šä¸‹æ–™é€Ÿåº¦ (v2.2)
        
        æ ¹æ®è®¾å¤‡ç±»å‹è¿”å›å›ºå®šçš„ä¸‹æ–™é€Ÿåº¦:
        - çª‘7654 (short_hopper_1/2/3/4): 10 kg/h
        - çª‘839 (long_hopper_1/2/3): 22 kg/h
        
        Args:
            device_id: è®¾å¤‡ID
            
        Returns:
            float: ä¸‹æ–™é€Ÿåº¦ (kg/ç§’)
        """
        if device_id.startswith("short_hopper"):
            return self.feed_rate_short_hopper  # 10 kg/h
        elif device_id.startswith("long_hopper"):
            return self.feed_rate_long_hopper   # 22 kg/h
        else:
            # é»˜è®¤å€¼ (ä¸åº”è¯¥åˆ°è¿™é‡Œ)
            return self.feed_rate_short_hopper

    def _calculate_consumption_rate(self, records: List[Dict], valley_idx: int, lookback: int = 5) -> float:
        """
        è®¡ç®—æŠ•æ–™å‰çš„å¹³å‡æ¶ˆè€—é€Ÿç‡ (å·²åºŸå¼ƒ - v2.2 ä½¿ç”¨å›ºå®šä¸‹æ–™é€Ÿåº¦)
        
        ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºå‘åå…¼å®¹ï¼Œå®é™…ä¸å†ä½¿ç”¨
        """
        return 0.0  # ä¸å†ä½¿ç”¨åŠ¨æ€è®¡ç®—

    def _filter_outliers(self, records: List[Dict], threshold: float = 3.0) -> List[Dict]:
        """
        è¿‡æ»¤å¼‚å¸¸å€¼ (å·²åºŸå¼ƒ - v2.2 ä¸å†ä½¿ç”¨)
        
        ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºå‘åå…¼å®¹
        """
        return records  # ä¸å†ä½¿ç”¨å¼‚å¸¸å€¼è¿‡æ»¤

    def _save_feeding_records(self, points: List[Point]):
        """
        ä¿å­˜æŠ•æ–™è®°å½•åˆ° InfluxDB
        
        æ³¨æ„: InfluxDB åŸºäº (measurement, tags, timestamp) çš„ç»„åˆå®ç°å¤©ç„¶å»é‡
        ç›¸åŒæ—¶é—´æˆ³çš„è®°å½•ä¼šè¢«è‡ªåŠ¨è¦†ç›–ï¼Œæ— éœ€æ‰‹åŠ¨å»é‡
        """
        try:
            write_api = self.history_service.client.write_api(write_options=SYNCHRONOUS)
            write_api.write(bucket=settings.influx_bucket, record=points)
            print(f"   ğŸ’¾ å·²ä¿å­˜ {len(points)} æ¡æŠ•æ–™è®°å½•åˆ° InfluxDB")
        except Exception as e:
            print(f"   âŒ ä¿å­˜æŠ•æ–™è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

# ============================================================
# å•ä¾‹å¯¼å‡º
# ============================================================
feeding_service = FeedingAnalysisService()


# ============================================================
# æ‰‹åŠ¨è§¦å‘åˆ†æ (ç”¨äºæµ‹è¯•)
# ============================================================
async def manual_analyze_feeding(device_ids: Optional[List[str]] = None):
    """
    æ‰‹åŠ¨è§¦å‘æŠ•æ–™åˆ†æ (ç”¨äºæµ‹è¯•æˆ–å‰ç«¯æ‰‹åŠ¨åˆ·æ–°)
    
    Args:
        device_ids: æŒ‡å®šè®¾å¤‡IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåˆ†ææ‰€æœ‰è®¾å¤‡
        
    Returns:
        Dict: åˆ†æç»“æœç»Ÿè®¡
    """
    service = FeedingAnalysisService()
    
    now = datetime.now(timezone.utc)
    start_time = now - timedelta(minutes=service.query_window_minutes)
    
    if device_ids is None:
        device_ids = service._get_hopper_devices()
    
    results = []
    stats = {
        "total_devices": len(device_ids),
        "devices_with_events": 0,
        "total_events": 0,
        "details": []
    }
    
    for device_id in device_ids:
        records = service._query_history_weights(device_id, start_time, now)
        if not records:
            continue
        
        feeding_events = service._detect_and_calculate_feeding(records, device_id)
        if feeding_events:
            results.extend(feeding_events)
            stats["devices_with_events"] += 1
            stats["total_events"] += len(feeding_events)
            stats["details"].append({
                "device_id": device_id,
                "events_count": len(feeding_events)
            })
    
    if results:
        service._save_feeding_records(results)
    
    return stats
