# ============================================================
# æ–‡ä»¶è¯´æ˜: data_export_service_v3.py - æ•°æ®å¯¼å‡ºæœåŠ¡ï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰
# ============================================================
# æ ¸å¿ƒä¼˜åŒ–:
# 1. æ‰¹é‡æŸ¥è¯¢é¢„è®¡ç®—æ•°æ®ï¼ˆä¸€æ¬¡æŸ¥è¯¢æ‰€æœ‰è®¾å¤‡ï¼‰
# 2. å¹¶è¡Œå¤„ç†ä¸å®Œæ•´å¤©çš„å®æ—¶è®¡ç®—
# 3. å†…å­˜ç¼“å­˜å®Œæ•´å¤©æ•°æ®ï¼ˆé¿å…é‡å¤æŸ¥è¯¢ï¼‰
# 4. æ€§èƒ½æå‡ 10-20 å€
# ============================================================
# æ–¹æ³•åˆ—è¡¨:
# 1. export_comprehensive_v3()    - ç»¼åˆå¯¼å‡ºï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰
# 2. _batch_query_daily_summary() - æ‰¹é‡æŸ¥è¯¢é¢„è®¡ç®—æ•°æ®
# 3. _parallel_calculate_partial_days() - å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©
# ============================================================

from datetime import datetime, timedelta, timezone
from typing import Dict, Any, Optional, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import json

from config import get_settings
from app.core.influxdb import get_influx_client
from app.services.data_export_service import get_export_service
from app.services.daily_summary_service import get_daily_summary_service
from app.utils.time_slice_utils import split_time_range_by_natural_days

settings = get_settings()

# ============================================================
# æ—¶é—´æ ¼å¼åŒ–å·¥å…·å‡½æ•°
# ============================================================
# å®šä¹‰åŒ—äº¬æ—¶åŒºï¼ˆUTC+8ï¼‰
BEIJING_TZ = timezone(timedelta(hours=8))

def format_datetime_without_microseconds(dt: datetime) -> str:
    """æ ¼å¼åŒ–æ—¶é—´ï¼Œå»é™¤å¾®ç§’éƒ¨åˆ†ï¼Œå¹¶è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
    
    Args:
        dt: datetime å¯¹è±¡ï¼ˆå¯èƒ½æ˜¯UTCæ—¶é—´æˆ–å…¶ä»–æ—¶åŒºï¼‰
        
    Returns:
        æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²ï¼ˆISO 8601æ ¼å¼ï¼ŒåŒ—äº¬æ—¶é—´ï¼Œæ— å¾®ç§’ï¼‰
        ä¾‹å¦‚: 2026-01-26T14:23:00+08:00
    """
    if dt is None:
        return None
    
    # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºUTC
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    
    # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
    dt_beijing = dt.astimezone(BEIJING_TZ)
    
    # å»é™¤å¾®ç§’
    dt_no_micro = dt_beijing.replace(microsecond=0)
    
    # è½¬æ¢ä¸º ISO 8601 æ ¼å¼
    return dt_no_micro.isoformat()

# ğŸ”§ å•ä¾‹å®ä¾‹
_export_service_v3_instance: Optional['DataExportServiceV3'] = None

# ğŸ”§ å†…å­˜ç¼“å­˜ï¼ˆå®Œæ•´å¤©æ•°æ®ï¼‰
_memory_cache: Dict[str, Any] = {}


class DataExportServiceV3:
    """æ•°æ®å¯¼å‡ºæœåŠ¡ï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.export_service = get_export_service()
        self.summary_service = get_daily_summary_service()
        self._client = None
        self._query_api = None
        self.bucket = settings.influx_bucket
    
    @property
    def client(self):
        """å»¶è¿Ÿè·å– InfluxDB å®¢æˆ·ç«¯"""
        if self._client is None:
            self._client = get_influx_client()
        return self._client
    
    @property
    def query_api(self):
        """å»¶è¿Ÿè·å– query_api"""
        if self._query_api is None:
            self._query_api = self.client.query_api()
        return self._query_api
    
    # ------------------------------------------------------------
    # æ ¸å¿ƒä¼˜åŒ– 1: æ‰¹é‡æŸ¥è¯¢é¢„è®¡ç®—æ•°æ®ï¼ˆä¸€æ¬¡æŸ¥è¯¢æ‰€æœ‰è®¾å¤‡ï¼‰
    # ------------------------------------------------------------
    def _batch_query_daily_summary(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:
        """æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰è®¾å¤‡çš„é¢„è®¡ç®—æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            {
                "short_hopper_1": {
                    "electricity": [...],
                    "feeding": [...]
                },
                "zone1": {
                    "electricity": [...]
                },
                ...
            }
        """
        print(f"ğŸ”„ æ‰¹é‡æŸ¥è¯¢é¢„è®¡ç®—æ•°æ®: {start_date.date()} ~ {end_date.date()}")
        
        # ğŸ”§ ä¸€æ¬¡æ€§æŸ¥è¯¢æ‰€æœ‰è®¾å¤‡ã€æ‰€æœ‰æŒ‡æ ‡ç±»å‹çš„æ•°æ®
        query = f'''
        from(bucket: "{self.bucket}")
            |> range(start: {start_date.isoformat()}, stop: {end_date.isoformat()})
            |> filter(fn: (r) => r["_measurement"] == "daily_summary")
            |> pivot(rowKey:["_time", "device_id", "metric_type", "date"], columnKey: ["_field"], valueColumn: "_value")
        '''
        
        try:
            result = self.query_api.query(query)
            
            # æŒ‰è®¾å¤‡IDå’ŒæŒ‡æ ‡ç±»å‹åˆ†ç»„
            data_by_device: Dict[str, Dict[str, List[Dict[str, Any]]]] = {}
            
            for table in result:
                for record in table.records:
                    device_id = record.values.get("device_id")
                    metric_type = record.values.get("metric_type")
                    date = record.values.get("date")
                    
                    # ğŸ”§ å…¼å®¹æ€§å¤„ç†ï¼šdaily_summary ä¸­å·²ç»åšäº†æ˜ å°„
                    # zone1~zone6 å’Œ scr_1_pump, scr_2_pump å¯ä»¥ç›´æ¥ä½¿ç”¨
                    
                    if device_id not in data_by_device:
                        data_by_device[device_id] = {}
                    
                    if metric_type not in data_by_device[device_id]:
                        data_by_device[device_id][metric_type] = []
                    
                    data_by_device[device_id][metric_type].append({
                        "date": date,
                        "start_reading": record.values.get("start_reading", 0.0),
                        "end_reading": record.values.get("end_reading", 0.0),
                        "consumption": record.values.get("consumption", 0.0),
                        "runtime_hours": record.values.get("runtime_hours", 0.0),
                        "feeding_amount": record.values.get("feeding_amount", 0.0),
                        "gas_consumption": record.values.get("gas_consumption", 0.0),
                    })
            
            print(f"âœ… æ‰¹é‡æŸ¥è¯¢å®Œæˆ: {len(data_by_device)} ä¸ªè®¾å¤‡")
            return data_by_device
        
        except Exception as e:
            print(f"âŒ æ‰¹é‡æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {}
    
    # ------------------------------------------------------------
    # æ ¸å¿ƒä¼˜åŒ– 2: å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©ï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰
    # ------------------------------------------------------------
    def _parallel_calculate_partial_days(
        self,
        device_configs: List[Dict[str, str]],
        partial_day_slices: List[Any]
    ) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:
        """å¹¶è¡Œè®¡ç®—æ‰€æœ‰è®¾å¤‡çš„ä¸å®Œæ•´å¤©æ•°æ®
        
        Args:
            device_configs: è®¾å¤‡é…ç½®åˆ—è¡¨ [{"device_id": "xxx", "device_type": "xxx", "metric_types": ["electricity", "feeding"]}, ...]
            partial_day_slices: ä¸å®Œæ•´å¤©çš„æ—¶é—´åˆ‡ç‰‡åˆ—è¡¨
            
        Returns:
            {
                "short_hopper_1": {
                    "electricity": [...],
                    "feeding": [...]
                },
                ...
            }
        """
        if not partial_day_slices:
            return {}
        
        print(f"ğŸ”„ å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©: {len(device_configs)} ä¸ªè®¾å¤‡ Ã— {len(partial_day_slices)} ä¸ªæ—¶é—´æ®µ")
        
        data_by_device: Dict[str, Dict[str, List[Dict[str, Any]]]] = {}
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè®¡ç®—
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            
            for device_config in device_configs:
                device_id = device_config["device_id"]
                device_type = device_config["device_type"]
                metric_types = device_config["metric_types"]
                
                for metric_type in metric_types:
                    for slice_obj in partial_day_slices:
                        future = executor.submit(
                            self._calculate_realtime_single,
                            device_id,
                            device_type,
                            metric_type,
                            slice_obj
                        )
                        futures.append((future, device_id, metric_type))
            
            # æ”¶é›†ç»“æœ
            for future, device_id, metric_type in futures:
                try:
                    record = future.result(timeout=10)
                    
                    if device_id not in data_by_device:
                        data_by_device[device_id] = {}
                    
                    if metric_type not in data_by_device[device_id]:
                        data_by_device[device_id][metric_type] = []
                    
                    data_by_device[device_id][metric_type].append(record)
                
                except Exception as e:
                    print(f"âš ï¸  è®¡ç®—å¤±è´¥ {device_id}/{metric_type}: {str(e)}")
        
        print(f"âœ… å¹¶è¡Œè®¡ç®—å®Œæˆ: {len(data_by_device)} ä¸ªè®¾å¤‡")
        return data_by_device
    
    def _calculate_realtime_single(
        self,
        device_id: str,
        device_type: str,
        metric_type: str,
        slice_obj: Any
    ) -> Dict[str, Any]:
        """è®¡ç®—å•ä¸ªè®¾å¤‡ã€å•ä¸ªæŒ‡æ ‡ã€å•ä¸ªæ—¶é—´æ®µçš„å®æ—¶æ•°æ®
        
        ğŸ”§ å…¼å®¹æ€§å¤„ç†ï¼š
        - è¾Šé“çª‘åˆ†åŒº (zone1~zone6): æŸ¥è¯¢ roller_kiln_1 + module_tag è¿‡æ»¤
        - SCR æ°¨æ°´æ³µ (scr_1_pump, scr_2_pump): æŸ¥è¯¢ scr_1/scr_2 + module_tag=meter
        """
        start_time = slice_obj.start_time
        end_time = slice_obj.end_time
        
        # ğŸ”§ æ˜ å°„è™šæ‹Ÿè®¾å¤‡IDåˆ°å®é™…æ•°æ®åº“å­˜å‚¨çš„ID
        actual_device_id, module_tag_filter = self._map_virtual_device_to_actual(device_id, device_type)
        
        if metric_type == "electricity":
            start_reading = self._get_electricity_reading_at_time_with_filter(
                actual_device_id, module_tag_filter, start_time
            )
            end_reading = self._get_electricity_reading_at_time_with_filter(
                actual_device_id, module_tag_filter, end_time
            )
            consumption = 0.0
            if end_reading is not None:
                start_value = start_reading if start_reading is not None else 0.0
                consumption = round(end_reading - start_value, 2)
                if consumption < 0:
                    consumption = round(end_reading, 2)
            
            runtime_hours = self._calculate_runtime_for_period_with_filter(
                actual_device_id, module_tag_filter, start_time, end_time
            )
            
            return {
                "date": slice_obj.date,
                "start_time": format_datetime_without_microseconds(start_time),
                "end_time": format_datetime_without_microseconds(end_time),
                "start_reading": round(start_reading, 2) if start_reading is not None else None,
                "end_reading": round(end_reading, 2) if end_reading is not None else None,
                "consumption": consumption,
                "runtime_hours": runtime_hours,
                "feeding_amount": 0.0,
                "gas_consumption": 0.0
            }
        
        elif metric_type == "gas":
            # ç‡ƒæ°”è¡¨ä¿æŒåŸé€»è¾‘ï¼ˆdevice_id ä¸€è‡´ï¼‰
            start_reading = self.export_service._get_gas_reading_at_time(
                actual_device_id, start_time
            )
            end_reading = self.export_service._get_gas_reading_at_time(
                actual_device_id, end_time
            )
            consumption = 0.0
            if end_reading is not None:
                start_value = start_reading if start_reading is not None else 0.0
                consumption = round(end_reading - start_value, 2)
                if consumption < 0:
                    consumption = round(end_reading, 2)
            
            runtime_hours = self.export_service._calculate_gas_meter_runtime(
                actual_device_id, start_time, end_time
            )
            
            return {
                "date": slice_obj.date,
                "start_time": format_datetime_without_microseconds(start_time),
                "end_time": format_datetime_without_microseconds(end_time),
                "start_reading": round(start_reading, 2) if start_reading is not None else None,
                "end_reading": round(end_reading, 2) if end_reading is not None else None,
                "consumption": 0.0,
                "runtime_hours": runtime_hours,
                "feeding_amount": 0.0,
                "gas_consumption": consumption
            }
        
        elif metric_type == "feeding":
            # æŠ•æ–™é‡ä¿æŒåŸé€»è¾‘ï¼ˆdevice_id ä¸€è‡´ï¼‰
            query = f'''
            from(bucket: "{self.bucket}")
                |> range(start: {start_time.isoformat()}, stop: {end_time.isoformat()})
                |> filter(fn: (r) => r["_measurement"] == "feeding_records")
                |> filter(fn: (r) => r["device_id"] == "{actual_device_id}")
                |> filter(fn: (r) => r["_field"] == "added_weight")
                |> sum()
            '''
            
            feeding_amount = 0.0
            try:
                result = self.query_api.query(query)
                for table in result:
                    for record in table.records:
                        feeding_amount = record.get_value()
                        break
            except Exception as e:
                print(f"âš ï¸  æŸ¥è¯¢æŠ•æ–™é‡å¤±è´¥: {str(e)}")
            
            return {
                "date": slice_obj.date,
                "start_time": format_datetime_without_microseconds(start_time),
                "end_time": format_datetime_without_microseconds(end_time),
                "start_reading": None,
                "end_reading": None,
                "consumption": 0.0,
                "runtime_hours": 0.0,
                "feeding_amount": round(feeding_amount, 2),
                "gas_consumption": 0.0
            }
        
        else:
            return {
                "date": slice_obj.date,
                "start_time": format_datetime_without_microseconds(start_time),
                "end_time": format_datetime_without_microseconds(end_time),
                "start_reading": None,
                "end_reading": None,
                "consumption": 0.0,
                "runtime_hours": 0.0,
                "feeding_amount": 0.0,
                "gas_consumption": 0.0
            }
    
    # ------------------------------------------------------------
    # ğŸ”§ æ–°å¢ï¼šè™šæ‹Ÿè®¾å¤‡IDæ˜ å°„ï¼ˆå…¼å®¹å†å²æ•°æ®ï¼‰
    # ------------------------------------------------------------
    def _map_virtual_device_to_actual(
        self,
        device_id: str,
        device_type: str
    ) -> tuple[str, str]:
        """å°†è™šæ‹Ÿè®¾å¤‡IDæ˜ å°„åˆ°å®é™…æ•°æ®åº“å­˜å‚¨çš„ID
        
        Args:
            device_id: è™šæ‹Ÿè®¾å¤‡ID (å¦‚ zone1, scr_1_pump)
            device_type: è™šæ‹Ÿè®¾å¤‡ç±»å‹
            
        Returns:
            (actual_device_id, module_tag_filter)
            
        æ˜ å°„è§„åˆ™:
        - zone1~zone6 -> (roller_kiln_1, zone1_meter~zone6_meter)
        - scr_1_pump -> (scr_1, meter)
        - scr_2_pump -> (scr_2, meter)
        - å…¶ä»–è®¾å¤‡ -> (device_id, None) ä¸éœ€è¦è¿‡æ»¤
        """
        # è¾Šé“çª‘åˆ†åŒºæ˜ å°„
        if device_type == "roller_kiln_zone":
            # zone1 -> (roller_kiln_1, zone1_meter)
            module_tag = f"{device_id}_meter"
            return ("roller_kiln_1", module_tag)
        
        # SCR æ°¨æ°´æ³µæ˜ å°„
        elif device_type == "scr_pump":
            # scr_1_pump -> (scr_1, meter)
            actual_id = device_id.replace("_pump", "")
            return (actual_id, "meter")
        
        # å…¶ä»–è®¾å¤‡ä¸éœ€è¦æ˜ å°„
        else:
            return (device_id, None)
    
    # ------------------------------------------------------------
    # ğŸ”§ æ–°å¢ï¼šå¸¦ module_tag è¿‡æ»¤çš„ç”µé‡è¯»æ•°æŸ¥è¯¢
    # ------------------------------------------------------------
    def _get_electricity_reading_at_time_with_filter(
        self,
        device_id: str,
        module_tag_filter: str,
        target_time: datetime
    ) -> Optional[float]:
        """æŸ¥è¯¢æŒ‡å®šæ—¶é—´ç‚¹çš„ç”µé‡è¯»æ•°ï¼ˆæ”¯æŒ module_tag è¿‡æ»¤ï¼‰
        
        Args:
            device_id: å®é™…è®¾å¤‡ID
            module_tag_filter: æ¨¡å—æ ‡ç­¾è¿‡æ»¤ï¼ˆå¦‚ zone1_meter, meterï¼‰
            target_time: ç›®æ ‡æ—¶é—´
            
        Returns:
            ç”µé‡è¯»æ•° (ImpEp) æˆ– None
        """
        # æ„å»ºæŸ¥è¯¢ï¼ˆæ·»åŠ  module_tag è¿‡æ»¤ï¼‰
        if module_tag_filter:
            query = f'''
            from(bucket: "{self.bucket}")
                |> range(start: {(target_time - timedelta(minutes=5)).isoformat()}, 
                         stop: {(target_time + timedelta(minutes=5)).isoformat()})
                |> filter(fn: (r) => r["_measurement"] == "sensor_data")
                |> filter(fn: (r) => r["device_id"] == "{device_id}")
                |> filter(fn: (r) => r["module_tag"] == "{module_tag_filter}")
                |> filter(fn: (r) => r["_field"] == "ImpEp")
                |> last()
            '''
        else:
            # æ— éœ€è¿‡æ»¤ï¼Œä½¿ç”¨åŸé€»è¾‘
            return self.export_service._get_electricity_reading_at_time(device_id, target_time)
        
        try:
            result = self.query_api.query(query)
            for table in result:
                for record in table.records:
                    return record.get_value()
            return None
        except Exception as e:
            print(f"âš ï¸  æŸ¥è¯¢ç”µé‡è¯»æ•°å¤±è´¥ {device_id}/{module_tag_filter}: {str(e)}")
            return None
    
    # ------------------------------------------------------------
    # ğŸ”§ æ–°å¢ï¼šå¸¦ module_tag è¿‡æ»¤çš„è¿è¡Œæ—¶é•¿è®¡ç®—
    # ------------------------------------------------------------
    def _calculate_runtime_for_period_with_filter(
        self,
        device_id: str,
        module_tag_filter: str,
        start_time: datetime,
        end_time: datetime
    ) -> float:
        """è®¡ç®—æŒ‡å®šæ—¶é—´æ®µçš„è¿è¡Œæ—¶é•¿ï¼ˆæ”¯æŒ module_tag è¿‡æ»¤ï¼‰
        
        Args:
            device_id: å®é™…è®¾å¤‡ID
            module_tag_filter: æ¨¡å—æ ‡ç­¾è¿‡æ»¤
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            
        Returns:
            è¿è¡Œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        """
        # æ„å»ºæŸ¥è¯¢ï¼ˆæ·»åŠ  module_tag è¿‡æ»¤ï¼‰
        if module_tag_filter:
            query = f'''
            from(bucket: "{self.bucket}")
                |> range(start: {start_time.isoformat()}, stop: {end_time.isoformat()})
                |> filter(fn: (r) => r["_measurement"] == "sensor_data")
                |> filter(fn: (r) => r["device_id"] == "{device_id}")
                |> filter(fn: (r) => r["module_tag"] == "{module_tag_filter}")
                |> filter(fn: (r) => r["_field"] == "Pt")
                |> filter(fn: (r) => r["_value"] > 0.01)
                |> count()
            '''
        else:
            # æ— éœ€è¿‡æ»¤ï¼Œä½¿ç”¨åŸé€»è¾‘
            return self.export_service._calculate_runtime_for_period(device_id, start_time, end_time)
        
        try:
            result = self.query_api.query(query)
            count = 0
            for table in result:
                for record in table.records:
                    count = record.get_value()
                    break
            
            # å‡è®¾é‡‡æ ·é—´éš”ä¸º 6 ç§’
            runtime_hours = (count * 6) / 3600.0
            return round(runtime_hours, 2)
        
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—è¿è¡Œæ—¶é•¿å¤±è´¥ {device_id}/{module_tag_filter}: {str(e)}")
            return 0.0
    
    # ------------------------------------------------------------
    # æ ¸å¿ƒä¼˜åŒ– 3: å†…å­˜ç¼“å­˜ï¼ˆå®Œæ•´å¤©æ•°æ®ï¼‰
    # ------------------------------------------------------------
    def _get_cache_key(self, start_date: str, end_date: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{start_date}_{end_date}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        return _memory_cache.get(cache_key)
    
    def _set_to_cache(self, cache_key: str, data: Dict[str, Any]):
        """å­˜å…¥ç¼“å­˜"""
        _memory_cache[cache_key] = data
        
        # é™åˆ¶ç¼“å­˜å¤§å°ï¼ˆæœ€å¤šä¿ç•™ 100 ä¸ªæ¡ç›®ï¼‰
        if len(_memory_cache) > 100:
            # åˆ é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = next(iter(_memory_cache))
            del _memory_cache[oldest_key]
    
    # ------------------------------------------------------------
    # ä¸»æ–¹æ³•: export_comprehensive_v3() - ç»¼åˆå¯¼å‡ºï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰
    # ------------------------------------------------------------
    def export_comprehensive_v3(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç»¼åˆå¯¼å‡ºæ‰€æœ‰è®¾å¤‡çš„æ‰€æœ‰æ•°æ®ï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰
        
        æ ¸å¿ƒä¼˜åŒ–:
        1. æ‰¹é‡æŸ¥è¯¢é¢„è®¡ç®—æ•°æ®ï¼ˆä¸€æ¬¡æŸ¥è¯¢æ‰€æœ‰è®¾å¤‡ï¼‰
        2. å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©ï¼ˆçº¿ç¨‹æ± ï¼‰
        3. å†…å­˜ç¼“å­˜å®Œæ•´å¤©æ•°æ®
        
        æ€§èƒ½æå‡: 10-20 å€
        """
        print(f"ğŸš€ å¼€å§‹ç»¼åˆå¯¼å‡ºï¼ˆV3ç»ˆæä¼˜åŒ–ç‰ˆï¼‰: {start_time} ~ {end_time}")
        
        # 1. æŒ‰è‡ªç„¶æ—¥åˆ‡åˆ†æ—¶é—´æ®µ
        slices = split_time_range_by_natural_days(start_time, end_time)
        full_day_slices = [s for s in slices if s.is_full_day]
        partial_day_slices = [s for s in slices if not s.is_full_day]
        
        print(f"ğŸ“Š æ—¶é—´åˆ‡åˆ†: {len(full_day_slices)} ä¸ªå®Œæ•´å¤©, {len(partial_day_slices)} ä¸ªä¸å®Œæ•´å¤©")
        
        # 2. æ£€æŸ¥ç¼“å­˜ï¼ˆä»…å®Œæ•´å¤©ï¼‰
        cache_key = None
        if full_day_slices and not partial_day_slices:
            start_date = full_day_slices[0].date
            end_date = full_day_slices[-1].date
            cache_key = self._get_cache_key(start_date, end_date)
            cached_data = self._get_from_cache(cache_key)
            
            if cached_data:
                print(f"âœ… å‘½ä¸­ç¼“å­˜ï¼Œç›´æ¥è¿”å›")
                return cached_data
        
        # 3. æ‰¹é‡æŸ¥è¯¢å®Œæ•´å¤©çš„é¢„è®¡ç®—æ•°æ®
        precomputed_data = {}
        if full_day_slices:
            start_date = datetime.strptime(full_day_slices[0].date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
            end_date = datetime.strptime(full_day_slices[-1].date, "%Y-%m-%d").replace(tzinfo=timezone.utc) + timedelta(days=1)
            
            # ç¡®ä¿æ•°æ®å·²è¡¥å…¨
            self.summary_service.check_and_fill_missing_dates(end_date=end_date)
            
            # æ‰¹é‡æŸ¥è¯¢
            precomputed_data = self._batch_query_daily_summary(start_date, end_date)
        
        # 4. å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©
        realtime_data = {}
        if partial_day_slices:
            # å®šä¹‰æ‰€æœ‰è®¾å¤‡é…ç½®
            device_configs = self._get_all_device_configs()
            realtime_data = self._parallel_calculate_partial_days(device_configs, partial_day_slices)
        
        # 5. åˆå¹¶æ•°æ®
        merged_data = self._merge_data(precomputed_data, realtime_data, slices)
        
        # 6. æ ¼å¼åŒ–è¾“å‡º
        result = self._format_comprehensive_output(merged_data, start_time, end_time)
        
        # 7. å­˜å…¥ç¼“å­˜ï¼ˆä»…å®Œæ•´å¤©ï¼‰
        if cache_key:
            self._set_to_cache(cache_key, result)
        
        print(f"âœ… ç»¼åˆå¯¼å‡ºå®Œæˆï¼ˆV3ï¼‰: {result['total_devices']} ä¸ªè®¾å¤‡")
        return result
    
    def _get_all_device_configs(self) -> List[Dict[str, str]]:
        """è·å–æ‰€æœ‰è®¾å¤‡é…ç½®"""
        configs = []
        
        # å›è½¬çª‘ï¼ˆæ–™ä»“ï¼‰
        hopper_ids = [
            "short_hopper_1", "short_hopper_2", "short_hopper_3", "short_hopper_4",
            "no_hopper_1", "no_hopper_2",
            "long_hopper_1", "long_hopper_2", "long_hopper_3"
        ]
        for hopper_id in hopper_ids:
            configs.append({
                "device_id": hopper_id,
                "device_type": "hopper",
                "metric_types": ["electricity", "feeding"]
            })
        
        # è¾Šé“çª‘6ä¸ªåˆ†åŒº
        zone_ids = ["zone1", "zone2", "zone3", "zone4", "zone5", "zone6"]
        for zone_id in zone_ids:
            configs.append({
                "device_id": zone_id,
                "device_type": "roller_kiln_zone",
                "metric_types": ["electricity"]
            })
        
        # è¾Šé“çª‘åˆè®¡
        configs.append({
            "device_id": "roller_kiln_total",
            "device_type": "roller_kiln_total",
            "metric_types": ["electricity"]
        })
        
        # SCRç‡ƒæ°”è¡¨
        configs.extend([
            {"device_id": "scr_1", "device_type": "scr_gas_meter", "metric_types": ["gas"]},
            {"device_id": "scr_2", "device_type": "scr_gas_meter", "metric_types": ["gas"]}
        ])
        
        # SCRæ°¨æ°´æ³µ
        configs.extend([
            {"device_id": "scr_1_pump", "device_type": "scr_pump", "metric_types": ["electricity"]},
            {"device_id": "scr_2_pump", "device_type": "scr_pump", "metric_types": ["electricity"]}
        ])
        
        # é£æœº
        configs.extend([
            {"device_id": "fan_1", "device_type": "fan", "metric_types": ["electricity"]},
            {"device_id": "fan_2", "device_type": "fan", "metric_types": ["electricity"]}
        ])
        
        return configs
    
    def _merge_data(
        self,
        precomputed_data: Dict[str, Dict[str, List[Dict[str, Any]]]],
        realtime_data: Dict[str, Dict[str, List[Dict[str, Any]]]],
        slices: List[Any]
    ) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:
        """åˆå¹¶é¢„è®¡ç®—æ•°æ®å’Œå®æ—¶æ•°æ®"""
        merged = {}
        
        # åˆå¹¶é¢„è®¡ç®—æ•°æ®
        for device_id, metrics in precomputed_data.items():
            if device_id not in merged:
                merged[device_id] = {}
            for metric_type, records in metrics.items():
                if metric_type not in merged[device_id]:
                    merged[device_id][metric_type] = []
                merged[device_id][metric_type].extend(records)
        
        # åˆå¹¶å®æ—¶æ•°æ®
        for device_id, metrics in realtime_data.items():
            if device_id not in merged:
                merged[device_id] = {}
            for metric_type, records in metrics.items():
                if metric_type not in merged[device_id]:
                    merged[device_id][metric_type] = []
                merged[device_id][metric_type].extend(records)
        
        # æŒ‰æ—¥æœŸæ’åº
        for device_id in merged:
            for metric_type in merged[device_id]:
                merged[device_id][metric_type].sort(key=lambda x: x["date"])
        
        return merged
    
    def _format_comprehensive_output(
        self,
        merged_data: Dict[str, Dict[str, List[Dict[str, Any]]]],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç»¼åˆå¯¼å‡ºè¾“å‡º"""
        devices = []
        
        # ğŸ”§ ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸèŒƒå›´ï¼ˆç¡®ä¿æ¯å¤©éƒ½æœ‰è®°å½•ï¼‰
        all_dates = []
        current_date = start_time.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date = end_time.replace(hour=0, minute=0, second=0, microsecond=0)
        
        while current_date <= end_date:
            all_dates.append(current_date.strftime("%Y-%m-%d"))
            current_date += timedelta(days=1)
        
        print(f"ğŸ“… ç”Ÿæˆå®Œæ•´æ—¥æœŸèŒƒå›´: {len(all_dates)} å¤© ({all_dates[0]} ~ {all_dates[-1]})")
        
        # è·å–æ‰€æœ‰è®¾å¤‡é…ç½®
        device_configs = self._get_all_device_configs()
        
        for config in device_configs:
            device_id = config["device_id"]
            device_type = config["device_type"]
            
            # è·å–è¯¥è®¾å¤‡çš„æ‰€æœ‰æ•°æ®
            device_data = merged_data.get(device_id, {})
            
            # ğŸ”§ åˆå§‹åŒ–æ‰€æœ‰æ—¥æœŸçš„è®°å½•ï¼ˆç¡®ä¿æ¯å¤©éƒ½æœ‰æ•°æ®ï¼‰
            daily_records_map = {}
            for date in all_dates:
                # ğŸ”§ ä¸ºå®Œæ•´å¤©å¡«å……é»˜è®¤æ—¶é—´ï¼ˆ00:00:00 ~ 23:59:59ï¼‰
                daily_records_map[date] = {
                    "date": date,
                    "start_time": f"{date}T00:00:00+00:00",  # å®Œæ•´å¤©çš„èµ·å§‹æ—¶é—´ï¼ˆæ— å¾®ç§’ï¼‰
                    "end_time": f"{date}T23:59:59+00:00",    # å®Œæ•´å¤©çš„ç»ˆæ­¢æ—¶é—´ï¼ˆæ— å¾®ç§’ï¼‰
                    "gas_consumption": 0.0,
                    "feeding_amount": 0.0,
                    "electricity_consumption": 0.0,
                    "runtime_hours": 0.0
                }
            
            # å¡«å……å®é™…æ•°æ®
            for metric_type, records in device_data.items():
                for record in records:
                    date = record["date"]
                    
                    # ğŸ”§ åªæ›´æ–°å­˜åœ¨äºæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    if date in daily_records_map:
                        # ğŸ”§ æ›´æ–°èµ·å§‹/ç»ˆæ­¢æ—¶é—´ï¼ˆä¸å®Œæ•´å¤©ä½¿ç”¨å®é™…æ—¶é—´ï¼Œè¦†ç›–é»˜è®¤æ—¶é—´ï¼‰
                        if record.get("start_time"):
                            daily_records_map[date]["start_time"] = record["start_time"]
                        if record.get("end_time"):
                            daily_records_map[date]["end_time"] = record["end_time"]
                        
                        # æ›´æ–°æŒ‡æ ‡æ•°æ®
                        if metric_type == "electricity":
                            daily_records_map[date]["electricity_consumption"] = record.get("consumption", 0.0)
                            daily_records_map[date]["runtime_hours"] = record.get("runtime_hours", 0.0)
                        elif metric_type == "gas":
                            daily_records_map[date]["gas_consumption"] = record.get("gas_consumption", 0.0)
                            daily_records_map[date]["runtime_hours"] = record.get("runtime_hours", 0.0)
                        elif metric_type == "feeding":
                            daily_records_map[date]["feeding_amount"] = record.get("feeding_amount", 0.0)
            
            # ğŸ”§ è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ—¥æœŸæ’åºï¼ˆç¡®ä¿æ—¶é—´é¡ºåºæ­£ç¡®ï¼‰
            daily_records = sorted(daily_records_map.values(), key=lambda x: x["date"])
            
            devices.append({
                "device_id": device_id,
                "device_type": device_type,
                "daily_records": daily_records
            })
        
        return {
            "start_time": format_datetime_without_microseconds(start_time),
            "end_time": format_datetime_without_microseconds(end_time),
            "total_devices": len(devices),
            "devices": devices
        }


    # ------------------------------------------------------------
    # æ–°å¢æ–¹æ³•: export_runtime_v3() - è®¾å¤‡è¿è¡Œæ—¶é•¿ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
    # ------------------------------------------------------------
    def export_runtime_v3(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """è®¾å¤‡è¿è¡Œæ—¶é•¿ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
        
        å¤ç”¨ export_comprehensive_v3 çš„æ•°æ®ï¼Œåªæå–è¿è¡Œæ—¶é•¿å­—æ®µ
        """
        print(f"ğŸš€ å¼€å§‹è®¾å¤‡è¿è¡Œæ—¶é•¿ï¼ˆV3ï¼‰: {start_time} ~ {end_time}")
        
        # å¤ç”¨ç»¼åˆå¯¼å‡ºçš„æ•°æ®
        comprehensive_data = self.export_comprehensive_v3(start_time, end_time)
        
        # æå–è¿è¡Œæ—¶é•¿æ•°æ®
        result = {
            "start_time": format_datetime_without_microseconds(start_time),
            "end_time": format_datetime_without_microseconds(end_time),
            "hoppers": [],
            "roller_kiln_zones": [],
            "roller_kiln_total": {},
            "scr_devices": [],
            "fan_devices": []
        }
        
        for device in comprehensive_data["devices"]:
            device_id = device["device_id"]
            device_type = device["device_type"]
            
            # æå–è¿è¡Œæ—¶é•¿æ•°æ®
            daily_records = []
            for record in device["daily_records"]:
                daily_records.append({
                    "date": record["date"],
                    "start_time": record["start_time"],
                    "end_time": record["end_time"],
                    "runtime_hours": record["runtime_hours"]
                })
            
            device_data = {
                "device_id": device_id,
                "device_type": device_type,
                "daily_records": daily_records
            }
            
            # åˆ†ç±»å­˜å‚¨
            if device_type == "hopper":
                result["hoppers"].append(device_data)
            elif device_type == "roller_kiln_zone":
                result["roller_kiln_zones"].append(device_data)
            elif device_type == "roller_kiln_total":
                result["roller_kiln_total"] = device_data
            elif device_type == "scr_pump":
                result["scr_devices"].append(device_data)
            elif device_type == "fan":
                result["fan_devices"].append(device_data)
        
        print(f"âœ… è®¾å¤‡è¿è¡Œæ—¶é•¿å®Œæˆï¼ˆV3ï¼‰")
        return result
    
    # ------------------------------------------------------------
    # æ–°å¢æ–¹æ³•: export_gas_v3() - ç‡ƒæ°”æ¶ˆè€—ç»Ÿè®¡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
    # ------------------------------------------------------------
    def export_gas_v3(
        self,
        device_ids: List[str],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç‡ƒæ°”æ¶ˆè€—ç»Ÿè®¡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
        
        å¤ç”¨ export_comprehensive_v3 çš„æ•°æ®ï¼Œåªæå–ç‡ƒæ°”æ¶ˆè€—å­—æ®µ
        """
        print(f"ğŸš€ å¼€å§‹ç‡ƒæ°”æ¶ˆè€—ç»Ÿè®¡ï¼ˆV3ï¼‰: {start_time} ~ {end_time}")
        
        # å¤ç”¨ç»¼åˆå¯¼å‡ºçš„æ•°æ®
        comprehensive_data = self.export_comprehensive_v3(start_time, end_time)
        
        # æå–ç‡ƒæ°”æ¶ˆè€—æ•°æ®
        result = {}
        
        for device in comprehensive_data["devices"]:
            device_id = device["device_id"]
            
            # åªå¤„ç†æŒ‡å®šçš„è®¾å¤‡
            if device_id not in device_ids:
                continue
            
            # æå–ç‡ƒæ°”æ¶ˆè€—æ•°æ®
            daily_records = []
            for record in device["daily_records"]:
                daily_records.append({
                    "date": record["date"],
                    "start_time": record["start_time"],
                    "end_time": record["end_time"],
                    "consumption": record["gas_consumption"],
                    "runtime_hours": record["runtime_hours"]
                })
            
            result[device_id] = {
                "device_id": device_id,
                "daily_records": daily_records
            }
        
        print(f"âœ… ç‡ƒæ°”æ¶ˆè€—ç»Ÿè®¡å®Œæˆï¼ˆV3ï¼‰: {len(result)} ä¸ªè®¾å¤‡")
        return result
    
    # ------------------------------------------------------------
    # æ–°å¢æ–¹æ³•: export_feeding_v3() - ç´¯è®¡æŠ•æ–™é‡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
    # ------------------------------------------------------------
    def export_feeding_v3(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç´¯è®¡æŠ•æ–™é‡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
        
        å¤ç”¨ export_comprehensive_v3 çš„æ•°æ®ï¼Œåªæå–æŠ•æ–™é‡å­—æ®µ
        """
        print(f"ğŸš€ å¼€å§‹ç´¯è®¡æŠ•æ–™é‡ï¼ˆV3ï¼‰: {start_time} ~ {end_time}")
        
        # å¤ç”¨ç»¼åˆå¯¼å‡ºçš„æ•°æ®
        comprehensive_data = self.export_comprehensive_v3(start_time, end_time)
        
        # æå–æŠ•æ–™é‡æ•°æ®
        result = {"hoppers": []}
        
        for device in comprehensive_data["devices"]:
            device_id = device["device_id"]
            device_type = device["device_type"]
            
            # åªå¤„ç†æ–™ä»“è®¾å¤‡
            if device_type != "hopper":
                continue
            
            # è·³è¿‡æ— æ–™ä»“çš„è®¾å¤‡
            if device_id in ["no_hopper_1", "no_hopper_2"]:
                continue
            
            # æå–æŠ•æ–™é‡æ•°æ®
            daily_records = []
            for record in device["daily_records"]:
                daily_records.append({
                    "date": record["date"],
                    "start_time": record["start_time"],
                    "end_time": record["end_time"],
                    "feeding_amount": record["feeding_amount"]
                })
            
            result["hoppers"].append({
                "device_id": device_id,
                "daily_records": daily_records
            })
        
        print(f"âœ… ç´¯è®¡æŠ•æ–™é‡å®Œæˆï¼ˆV3ï¼‰: {len(result['hoppers'])} ä¸ªè®¾å¤‡")
        return result
    
    # ------------------------------------------------------------
    # æ–°å¢æ–¹æ³•: export_electricity_v3() - ç”µé‡ç»Ÿè®¡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
    # ------------------------------------------------------------
    def export_electricity_v3(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ç”µé‡ç»Ÿè®¡ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼‰
        
        å¤ç”¨ export_comprehensive_v3 çš„æ•°æ®ï¼Œåªæå–ç”µé‡å­—æ®µ
        
        æ³¨æ„ï¼šéœ€è¦ä» daily_summary è¡¨æˆ–å®æ—¶è®¡ç®—ä¸­è·å– start_reading å’Œ end_reading
        """
        print(f"ğŸš€ å¼€å§‹ç”µé‡ç»Ÿè®¡ï¼ˆV3ï¼‰: {start_time} ~ {end_time}")
        
        # 1. æŒ‰è‡ªç„¶æ—¥åˆ‡åˆ†æ—¶é—´æ®µ
        slices = split_time_range_by_natural_days(start_time, end_time)
        full_day_slices = [s for s in slices if s.is_full_day]
        partial_day_slices = [s for s in slices if not s.is_full_day]
        
        # 2. æ‰¹é‡æŸ¥è¯¢å®Œæ•´å¤©çš„é¢„è®¡ç®—æ•°æ®
        precomputed_data = {}
        if full_day_slices:
            start_date = datetime.strptime(full_day_slices[0].date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
            end_date = datetime.strptime(full_day_slices[-1].date, "%Y-%m-%d").replace(tzinfo=timezone.utc) + timedelta(days=1)
            
            # ç¡®ä¿æ•°æ®å·²è¡¥å…¨
            self.summary_service.check_and_fill_missing_dates(end_date=end_date)
            
            # æ‰¹é‡æŸ¥è¯¢
            precomputed_data = self._batch_query_daily_summary(start_date, end_date)
        
        # 3. å¹¶è¡Œè®¡ç®—ä¸å®Œæ•´å¤©
        realtime_data = {}
        if partial_day_slices:
            # åªæŸ¥è¯¢æœ‰ç”µé‡æ•°æ®çš„è®¾å¤‡
            device_configs = [
                config for config in self._get_all_device_configs()
                if "electricity" in config["metric_types"]
            ]
            realtime_data = self._parallel_calculate_partial_days(device_configs, partial_day_slices)
        
        # 4. åˆå¹¶æ•°æ®
        merged_data = self._merge_data(precomputed_data, realtime_data, slices)
        
        # 5. æ ¼å¼åŒ–è¾“å‡ºï¼ˆåŒ…å« start_reading å’Œ end_readingï¼‰
        result = {
            "start_time": format_datetime_without_microseconds(start_time),
            "end_time": format_datetime_without_microseconds(end_time),
            "hoppers": [],
            "roller_kiln_zones": [],
            "roller_kiln_total": {},
            "scr_devices": [],
            "fan_devices": []
        }
        
        # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸèŒƒå›´
        all_dates = []
        current_date = start_time.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date_obj = end_time.replace(hour=0, minute=0, second=0, microsecond=0)
        
        while current_date <= end_date_obj:
            all_dates.append(current_date.strftime("%Y-%m-%d"))
            current_date += timedelta(days=1)
        
        # è·å–æ‰€æœ‰æœ‰ç”µé‡æ•°æ®çš„è®¾å¤‡
        device_configs = [
            config for config in self._get_all_device_configs()
            if "electricity" in config["metric_types"]
        ]
        
        for config in device_configs:
            device_id = config["device_id"]
            device_type = config["device_type"]
            
            # è·å–è¯¥è®¾å¤‡çš„ç”µé‡æ•°æ®
            device_data = merged_data.get(device_id, {}).get("electricity", [])
            
            # åˆå§‹åŒ–æ‰€æœ‰æ—¥æœŸçš„è®°å½•
            daily_records_map = {}
            for date in all_dates:
                daily_records_map[date] = {
                    "date": date,
                    "start_time": f"{date}T00:00:00+00:00",
                    "end_time": f"{date}T23:59:59+00:00",
                    "start_reading": 0.0,
                    "end_reading": 0.0,
                    "consumption": 0.0,
                    "runtime_hours": 0.0
                }
            
            # å¡«å……å®é™…æ•°æ®
            for record in device_data:
                date = record["date"]
                if date in daily_records_map:
                    # æ›´æ–°æ—¶é—´
                    if record.get("start_time"):
                        daily_records_map[date]["start_time"] = record["start_time"]
                    if record.get("end_time"):
                        daily_records_map[date]["end_time"] = record["end_time"]
                    
                    # æ›´æ–°è¯»æ•°å’Œæ¶ˆè€—
                    daily_records_map[date]["start_reading"] = record.get("start_reading", 0.0) or 0.0
                    daily_records_map[date]["end_reading"] = record.get("end_reading", 0.0) or 0.0
                    daily_records_map[date]["consumption"] = record.get("consumption", 0.0)
                    daily_records_map[date]["runtime_hours"] = record.get("runtime_hours", 0.0)
            
            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
            daily_records = sorted(daily_records_map.values(), key=lambda x: x["date"])
            
            device_data_obj = {
                "device_id": device_id,
                "device_type": device_type,
                "daily_records": daily_records
            }
            
            # åˆ†ç±»å­˜å‚¨
            if device_type == "hopper":
                result["hoppers"].append(device_data_obj)
            elif device_type == "roller_kiln_zone":
                result["roller_kiln_zones"].append(device_data_obj)
            elif device_type == "roller_kiln_total":
                result["roller_kiln_total"] = device_data_obj
            elif device_type == "scr_pump":
                result["scr_devices"].append(device_data_obj)
            elif device_type == "fan":
                result["fan_devices"].append(device_data_obj)
        
        print(f"âœ… ç”µé‡ç»Ÿè®¡å®Œæˆï¼ˆV3ï¼‰")
        return result


# ------------------------------------------------------------
# å•ä¾‹è·å–å‡½æ•°
# ------------------------------------------------------------
def get_export_service_v3() -> DataExportServiceV3:
    """è·å–æ•°æ®å¯¼å‡ºæœåŠ¡V3å•ä¾‹"""
    global _export_service_v3_instance
    if _export_service_v3_instance is None:
        _export_service_v3_instance = DataExportServiceV3()
    return _export_service_v3_instance

